{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/2_embeddings_raw_data.csv'\n",
    "\n",
    "# Read the TSV file into a pandas DataFrame\n",
    "df = pd.read_csv(filename, on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auid</th>\n",
       "      <th>name</th>\n",
       "      <th>EthnicSeer</th>\n",
       "      <th>prop</th>\n",
       "      <th>lastname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>Ethnea</th>\n",
       "      <th>Genni</th>\n",
       "      <th>SexMac</th>\n",
       "      <th>SSNgender</th>\n",
       "      <th>Highest_probF_ethnicity</th>\n",
       "      <th>Highest_probF_value</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9731334_2</td>\n",
       "      <td>Cameron 'Dale' Bass</td>\n",
       "      <td>ITA</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>'Dale' Bass</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>M</td>\n",
       "      <td>mostly_male</td>\n",
       "      <td>-</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>92.191</td>\n",
       "      <td>[0.0027535639237612486, -0.006899471394717693,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2155715_1</td>\n",
       "      <td>Bert Hart</td>\n",
       "      <td>ENG</td>\n",
       "      <td>0.772359</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Bert</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>M</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>87.200</td>\n",
       "      <td>[-0.012196633964776993, -0.034759119153022766,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14609221_2</td>\n",
       "      <td>Esther Nolte- Hoen</td>\n",
       "      <td>GER</td>\n",
       "      <td>0.665081</td>\n",
       "      <td>Nolte- Hoen</td>\n",
       "      <td>Esther</td>\n",
       "      <td>GERMAN</td>\n",
       "      <td>F</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>43.243</td>\n",
       "      <td>[-0.02559061162173748, -0.02379501983523369, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8101337_1</td>\n",
       "      <td>Ellen 't Hoen</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>'t Hoen</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>F</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>37.459</td>\n",
       "      <td>[-0.014605682343244553, -0.030205124989151955,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9804785_2</td>\n",
       "      <td>Peter 't Hoen</td>\n",
       "      <td>GER</td>\n",
       "      <td>0.330864</td>\n",
       "      <td>'t Hoen</td>\n",
       "      <td>Peter</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>M</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>GERMAN</td>\n",
       "      <td>34.203</td>\n",
       "      <td>[0.018846435472369194, -0.026805326342582703, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35887</th>\n",
       "      <td>9239360_5</td>\n",
       "      <td>Senda Mezghani</td>\n",
       "      <td>ARA</td>\n",
       "      <td>0.691154</td>\n",
       "      <td>Mezghani</td>\n",
       "      <td>Senda</td>\n",
       "      <td>ARAB</td>\n",
       "      <td>F</td>\n",
       "      <td>andy</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>60.288</td>\n",
       "      <td>[0.0009060240699909627, -0.012940743006765842,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35888</th>\n",
       "      <td>9258893_4</td>\n",
       "      <td>Raquelle Mesholam-Gately</td>\n",
       "      <td>FRN</td>\n",
       "      <td>0.671148</td>\n",
       "      <td>Mesholam-Gately</td>\n",
       "      <td>Raquelle</td>\n",
       "      <td>ENGLISH-HISPANIC</td>\n",
       "      <td>F</td>\n",
       "      <td>andy</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>99.978</td>\n",
       "      <td>[-0.009965583682060242, 0.001120477681979537, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35889</th>\n",
       "      <td>12621069_2</td>\n",
       "      <td>Niki Messini-Nikolaki</td>\n",
       "      <td>RUS</td>\n",
       "      <td>0.946401</td>\n",
       "      <td>Messini-Nikolaki</td>\n",
       "      <td>Niki</td>\n",
       "      <td>GREEK</td>\n",
       "      <td>F</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>GREEK</td>\n",
       "      <td>96.862</td>\n",
       "      <td>[-0.00857141800224781, -0.01564069651067257, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35890</th>\n",
       "      <td>3154416_5</td>\n",
       "      <td>Tahar Mestiri</td>\n",
       "      <td>FRN</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>Mestiri</td>\n",
       "      <td>Tahar</td>\n",
       "      <td>ARAB</td>\n",
       "      <td>M</td>\n",
       "      <td>male</td>\n",
       "      <td>-</td>\n",
       "      <td>ARAB</td>\n",
       "      <td>83.593</td>\n",
       "      <td>[-0.012485790997743607, -0.01225669402629137, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35891</th>\n",
       "      <td>16630685_2</td>\n",
       "      <td>Danesh Miah</td>\n",
       "      <td>IND</td>\n",
       "      <td>0.874113</td>\n",
       "      <td>Miah</td>\n",
       "      <td>Danesh</td>\n",
       "      <td>ARAB-INDIAN</td>\n",
       "      <td>M</td>\n",
       "      <td>andy</td>\n",
       "      <td>M</td>\n",
       "      <td>ARAB</td>\n",
       "      <td>61.104</td>\n",
       "      <td>[-0.020368045195937157, -0.0006314862985163927...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35892 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             auid                      name EthnicSeer      prop  \\\n",
       "0       9731334_2       Cameron 'Dale' Bass        ITA  0.653567   \n",
       "1       2155715_1                 Bert Hart        ENG  0.772359   \n",
       "2      14609221_2        Esther Nolte- Hoen        GER  0.665081   \n",
       "3       8101337_1             Ellen 't Hoen        CHI  0.665526   \n",
       "4       9804785_2             Peter 't Hoen        GER  0.330864   \n",
       "...           ...                       ...        ...       ...   \n",
       "35887   9239360_5            Senda Mezghani        ARA  0.691154   \n",
       "35888   9258893_4  Raquelle Mesholam-Gately        FRN  0.671148   \n",
       "35889  12621069_2     Niki Messini-Nikolaki        RUS  0.946401   \n",
       "35890   3154416_5             Tahar Mestiri        FRN  0.376373   \n",
       "35891  16630685_2               Danesh Miah        IND  0.874113   \n",
       "\n",
       "               lastname firstname            Ethnea Genni       SexMac  \\\n",
       "0           'Dale' Bass   Cameron           ENGLISH     M  mostly_male   \n",
       "1                  Hart      Bert             DUTCH     M         male   \n",
       "2           Nolte- Hoen    Esther            GERMAN     F       female   \n",
       "3               't Hoen     Ellen             DUTCH     F       female   \n",
       "4               't Hoen     Peter             DUTCH     M         male   \n",
       "...                 ...       ...               ...   ...          ...   \n",
       "35887          Mezghani     Senda              ARAB     F         andy   \n",
       "35888   Mesholam-Gately  Raquelle  ENGLISH-HISPANIC     F         andy   \n",
       "35889  Messini-Nikolaki      Niki             GREEK     F       female   \n",
       "35890           Mestiri     Tahar              ARAB     M         male   \n",
       "35891              Miah    Danesh       ARAB-INDIAN     M         andy   \n",
       "\n",
       "      SSNgender Highest_probF_ethnicity  Highest_probF_value  \\\n",
       "0             -                 ENGLISH               92.191   \n",
       "1             M                   DUTCH               87.200   \n",
       "2             F                HISPANIC               43.243   \n",
       "3             F                   DUTCH               37.459   \n",
       "4             M                  GERMAN               34.203   \n",
       "...         ...                     ...                  ...   \n",
       "35887         F                HISPANIC               60.288   \n",
       "35888         F                HISPANIC               99.978   \n",
       "35889         F                   GREEK               96.862   \n",
       "35890         -                    ARAB               83.593   \n",
       "35891         M                    ARAB               61.104   \n",
       "\n",
       "                                               Embedding  \n",
       "0      [0.0027535639237612486, -0.006899471394717693,...  \n",
       "1      [-0.012196633964776993, -0.034759119153022766,...  \n",
       "2      [-0.02559061162173748, -0.02379501983523369, -...  \n",
       "3      [-0.014605682343244553, -0.030205124989151955,...  \n",
       "4      [0.018846435472369194, -0.026805326342582703, ...  \n",
       "...                                                  ...  \n",
       "35887  [0.0009060240699909627, -0.012940743006765842,...  \n",
       "35888  [-0.009965583682060242, 0.001120477681979537, ...  \n",
       "35889  [-0.00857141800224781, -0.01564069651067257, 0...  \n",
       "35890  [-0.012485790997743607, -0.01225669402629137, ...  \n",
       "35891  [-0.020368045195937157, -0.0006314862985163927...  \n",
       "\n",
       "[35892 rows x 13 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embedding'] = df['Embedding'].apply(ast.literal_eval)\n",
    "df['Embedding'] = df['Embedding'].apply(lambda x: [float(num) for num in x])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some names with low probability of being in top ethnicities to have better class balance for clustering\n",
    "top_ethnicities = ['HISPANIC', 'ENGLISH', 'INDIAN', 'ARAB', 'CHINESE', 'JAPANESE', 'NORDIC', 'SLAV']\n",
    "df = df[~df[\"Highest_probF_ethnicity\"].isin(top_ethnicities) | ((df[\"Highest_probF_ethnicity\"].isin(top_ethnicities) & (df[\"Highest_probF_value\"] > 95)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ethnea_counts = df['Highest_probF_ethnicity'].value_counts()\n",
    "# print(ethnea_counts.to_string())\n",
    "# print(len(ethnea_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21813\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Embedding' column to a numpy array\n",
    "X = np.array(df['Embedding'].tolist())\n",
    "\n",
    "# Normalize the embeddings\n",
    "X_normalized = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/miniforge3/envs/debias/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 97  41  98 111 121 135 185  52  96 136]\n",
      "21813\n",
      "CPU times: user 11min 28s, sys: 7.73 s, total: 11min 35s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply K-means clustering\n",
    "df_copy = df.copy()\n",
    "kmeans = MiniBatchKMeans(n_clusters=200, random_state=0, batch_size=2048)\n",
    "kmeans.fit(X_normalized)\n",
    "\n",
    "y_kmeans = kmeans.predict(X_normalized)\n",
    "print(y_kmeans[0:10])\n",
    "print(len(y_kmeans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted embeddings saved to ../data/3_clusters_200.csv.\n"
     ]
    }
   ],
   "source": [
    "# Add 'Cluster' column to the copied DataFrame\n",
    "df_copy['Cluster'] = y_kmeans\n",
    "\n",
    "# Sort DataFrame by 'Cluster' column\n",
    "df_sorted = df_copy[['firstname', 'Cluster', 'Highest_probF_ethnicity', 'Highest_probF_value', 'Genni']].sort_values(by='Cluster')\n",
    "# Rename columns\n",
    "df_sorted.rename(columns={'Highest_probF_ethnicity': 'Ethnicity', 'Highest_probF_value': 'Ethnicity Probability', 'Genni': 'Gender'}, inplace=True)\n",
    "df_sorted['Group'] = list(zip(df_sorted['Ethnicity'], df_sorted['Gender']))\n",
    "\n",
    "# Save to csv\n",
    "csv_filename = '../data/3_clusters_200.csv'\n",
    "df_sorted.to_csv(csv_filename, index=False)\n",
    "print(f\"Sorted embeddings saved to {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Ethnicity Probability</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30514</th>\n",
       "      <td>Warwick</td>\n",
       "      <td>0</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>95.829</td>\n",
       "      <td>M</td>\n",
       "      <td>(ENGLISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14923</th>\n",
       "      <td>Hastings</td>\n",
       "      <td>0</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>77.214</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>York</td>\n",
       "      <td>0</td>\n",
       "      <td>GERMAN</td>\n",
       "      <td>85.464</td>\n",
       "      <td>M</td>\n",
       "      <td>(GERMAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>Stirling</td>\n",
       "      <td>0</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>95.523</td>\n",
       "      <td>M</td>\n",
       "      <td>(ENGLISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>Albion</td>\n",
       "      <td>0</td>\n",
       "      <td>ROMANIAN</td>\n",
       "      <td>61.645</td>\n",
       "      <td>M</td>\n",
       "      <td>(ROMANIAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>Dongwon</td>\n",
       "      <td>199</td>\n",
       "      <td>KOREAN</td>\n",
       "      <td>96.171</td>\n",
       "      <td>M</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837</th>\n",
       "      <td>Daehee</td>\n",
       "      <td>199</td>\n",
       "      <td>KOREAN</td>\n",
       "      <td>97.545</td>\n",
       "      <td>M</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>Dongmin</td>\n",
       "      <td>199</td>\n",
       "      <td>KOREAN</td>\n",
       "      <td>83.667</td>\n",
       "      <td>M</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17054</th>\n",
       "      <td>Daekwan</td>\n",
       "      <td>199</td>\n",
       "      <td>KOREAN</td>\n",
       "      <td>87.916</td>\n",
       "      <td>M</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17859</th>\n",
       "      <td>Donghoon</td>\n",
       "      <td>199</td>\n",
       "      <td>KOREAN</td>\n",
       "      <td>97.530</td>\n",
       "      <td>M</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21813 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname  Cluster Ethnicity  Ethnicity Probability Gender  \\\n",
       "30514   Warwick        0   ENGLISH                 95.829      M   \n",
       "14923  Hastings        0   AFRICAN                 77.214      M   \n",
       "10917      York        0    GERMAN                 85.464      M   \n",
       "7722   Stirling        0   ENGLISH                 95.523      M   \n",
       "20564    Albion        0  ROMANIAN                 61.645      M   \n",
       "...         ...      ...       ...                    ...    ...   \n",
       "10270   Dongwon      199    KOREAN                 96.171      M   \n",
       "18837    Daehee      199    KOREAN                 97.545      M   \n",
       "18838   Dongmin      199    KOREAN                 83.667      M   \n",
       "17054   Daekwan      199    KOREAN                 87.916      M   \n",
       "17859  Donghoon      199    KOREAN                 97.530      M   \n",
       "\n",
       "               Group  \n",
       "30514   (ENGLISH, M)  \n",
       "14923   (AFRICAN, M)  \n",
       "10917    (GERMAN, M)  \n",
       "7722    (ENGLISH, M)  \n",
       "20564  (ROMANIAN, M)  \n",
       "...              ...  \n",
       "10270    (KOREAN, M)  \n",
       "18837    (KOREAN, M)  \n",
       "18838    (KOREAN, M)  \n",
       "17054    (KOREAN, M)  \n",
       "17859    (KOREAN, M)  \n",
       "\n",
       "[21813 rows x 6 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Size</th>\n",
       "      <th>Group</th>\n",
       "      <th>Group_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>223</td>\n",
       "      <td>(TURKISH, F)</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>186</td>\n",
       "      <td>(ISRAELI, F)</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>152</td>\n",
       "      <td>(HISPANIC, M)</td>\n",
       "      <td>9.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>(DUTCH, M)</td>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167</td>\n",
       "      <td>82</td>\n",
       "      <td>(GERMAN, M)</td>\n",
       "      <td>9.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>103</td>\n",
       "      <td>122</td>\n",
       "      <td>(JAPANESE, M)</td>\n",
       "      <td>94.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>176</td>\n",
       "      <td>82</td>\n",
       "      <td>(JAPANESE, M)</td>\n",
       "      <td>95.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>155</td>\n",
       "      <td>141</td>\n",
       "      <td>(INDIAN, M)</td>\n",
       "      <td>99.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>(KOREAN, M)</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>(JAPANESE, F)</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cluster  Size          Group  Group_Acc\n",
       "0        113   223   (TURKISH, F)       7.17\n",
       "1         84   186   (ISRAELI, F)       8.06\n",
       "2         80   152  (HISPANIC, M)       9.21\n",
       "3         43    52     (DUTCH, M)       9.62\n",
       "4        167    82    (GERMAN, M)       9.76\n",
       "..       ...   ...            ...        ...\n",
       "195      103   122  (JAPANESE, M)      94.26\n",
       "196      176    82  (JAPANESE, M)      95.12\n",
       "197      155   141    (INDIAN, M)      99.29\n",
       "198      112    20    (KOREAN, M)     100.00\n",
       "199      198     1  (JAPANESE, F)     100.00\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creates a df with information about each cluster\n",
    "\n",
    "cluster_sizes = df_sorted['Cluster'].value_counts().reset_index().rename(columns={'index': 'Cluster', 'Cluster': 'Size'})\n",
    "\n",
    "# Find the group with the highest count for each cluster\n",
    "highest_group = df_sorted.groupby('Cluster')['Group'].apply(lambda x: x.value_counts().idxmax()).reset_index(name='Group')\n",
    "\n",
    "# Calculate the percentage of rows with the highest group for each cluster\n",
    "highest_group_percent = df_sorted.groupby('Cluster')['Group'].apply(lambda x: (x.value_counts(normalize=True).max() * 100).round(2)).reset_index(name='Group_Acc')\n",
    "\n",
    "# Merge the DataFrames\n",
    "result_df = pd.merge(cluster_sizes, highest_group, on='Cluster')\n",
    "result_df = pd.merge(result_df, highest_group_percent, on='Cluster')\n",
    "\n",
    "result_df = result_df.sort_values(by='Group_Acc').reset_index(drop=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cluster  Size          Group  Group_Acc\n",
      "76       42   145  (JAPANESE, F)      93.10\n",
      "77      103   122  (JAPANESE, M)      94.26\n",
      "78      176    82  (JAPANESE, M)      95.12\n",
      "79      155   141    (INDIAN, M)      99.29\n",
      "80      112    20    (KOREAN, M)     100.00\n",
      "Average Cluster Size: 121.58024691358025\n"
     ]
    }
   ],
   "source": [
    "## Only takes clusters with high ethnicity/gender agreement\n",
    "\n",
    "# Filter clusters with Ethnicity and Gender Acc > 50%\n",
    "chosen_clusters = result_df[(result_df['Group_Acc'] > 50)]\n",
    "\n",
    "# Only keep size of 10 or above\n",
    "chosen_clusters = chosen_clusters[chosen_clusters['Size'] > 9]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(chosen_clusters.reset_index(drop=True).tail())\n",
    "print(\"Average Cluster Size: \" + str(chosen_clusters['Size'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Ethnicity Probability</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oladipo</td>\n",
       "      <td>122</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>94.404</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adebowale</td>\n",
       "      <td>122</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>99.733</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adedeji</td>\n",
       "      <td>122</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>92.914</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olumide</td>\n",
       "      <td>122</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>85.657</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obafemi</td>\n",
       "      <td>122</td>\n",
       "      <td>AFRICAN</td>\n",
       "      <td>97.160</td>\n",
       "      <td>M</td>\n",
       "      <td>(AFRICAN, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Ozgen</td>\n",
       "      <td>76</td>\n",
       "      <td>TURKISH</td>\n",
       "      <td>99.991</td>\n",
       "      <td>M</td>\n",
       "      <td>(TURKISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Osman</td>\n",
       "      <td>76</td>\n",
       "      <td>TURKISH</td>\n",
       "      <td>96.523</td>\n",
       "      <td>M</td>\n",
       "      <td>(TURKISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Murat</td>\n",
       "      <td>76</td>\n",
       "      <td>TURKISH</td>\n",
       "      <td>98.830</td>\n",
       "      <td>M</td>\n",
       "      <td>(TURKISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Suleyman</td>\n",
       "      <td>76</td>\n",
       "      <td>TURKISH</td>\n",
       "      <td>99.263</td>\n",
       "      <td>M</td>\n",
       "      <td>(TURKISH, M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Davut</td>\n",
       "      <td>76</td>\n",
       "      <td>TURKISH</td>\n",
       "      <td>99.659</td>\n",
       "      <td>M</td>\n",
       "      <td>(TURKISH, M)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     firstname  Cluster Ethnicity  Ethnicity Probability Gender         Group\n",
       "0      Oladipo      122   AFRICAN                 94.404      M  (AFRICAN, M)\n",
       "1    Adebowale      122   AFRICAN                 99.733      M  (AFRICAN, M)\n",
       "2      Adedeji      122   AFRICAN                 92.914      M  (AFRICAN, M)\n",
       "3      Olumide      122   AFRICAN                 85.657      M  (AFRICAN, M)\n",
       "4      Obafemi      122   AFRICAN                 97.160      M  (AFRICAN, M)\n",
       "..         ...      ...       ...                    ...    ...           ...\n",
       "325      Ozgen       76   TURKISH                 99.991      M  (TURKISH, M)\n",
       "326      Osman       76   TURKISH                 96.523      M  (TURKISH, M)\n",
       "327      Murat       76   TURKISH                 98.830      M  (TURKISH, M)\n",
       "328   Suleyman       76   TURKISH                 99.263      M  (TURKISH, M)\n",
       "329      Davut       76   TURKISH                 99.659      M  (TURKISH, M)\n",
       "\n",
       "[330 rows x 6 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = chosen_clusters.groupby(['Group'])\n",
    "selected_rows_df = pd.DataFrame()\n",
    "\n",
    "for group_id, (group_label, group_data) in enumerate(grouped_df):\n",
    "    cluster_list = group_data['Cluster'].to_list()\n",
    "\n",
    "    # Find all matching rows in 'results_df' with the same 'Group'\n",
    "    # from a list of clusters\n",
    "    matching_rows = df_sorted[\n",
    "        (df_sorted['Group'] == group_label) &\n",
    "        (df_sorted['Cluster'].isin(cluster_list))\n",
    "    ]\n",
    "\n",
    "    # Take a random 10 rows from the matching rows\n",
    "    selected_rows = matching_rows.sample(n=10, random_state=32)\n",
    "\n",
    "    # Concatenate the selected rows with the 'selected_rows_df' DataFrame\n",
    "    selected_rows_df = pd.concat([selected_rows_df, selected_rows], ignore_index=True)\n",
    "\n",
    "\n",
    "selected_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AFRICAN', 'F')\n",
      "('AFRICAN', 'M')\n",
      "('ARAB', 'F')\n",
      "('ARAB', 'M')\n",
      "('BALTIC', 'F')\n",
      "('BALTIC', 'M')\n",
      "('CHINESE', 'F')\n",
      "('CHINESE', 'M')\n",
      "('DUTCH', 'F')\n",
      "('DUTCH', 'M')\n",
      "('ENGLISH', 'F')\n",
      "('ENGLISH', 'M')\n",
      "('FRENCH', 'F')\n",
      "('FRENCH', 'M')\n",
      "('GERMAN', 'F')\n",
      "('GERMAN', 'M')\n",
      "('GREEK', 'F')\n",
      "('GREEK', 'M')\n",
      "('HISPANIC', 'F')\n",
      "('HISPANIC', 'M')\n",
      "('HUNGARIAN', 'F')\n",
      "('HUNGARIAN', 'M')\n",
      "('INDIAN', 'F')\n",
      "('INDIAN', 'M')\n",
      "('ISRAELI', 'F')\n",
      "('ISRAELI', 'M')\n",
      "('ITALIAN', 'F')\n",
      "('ITALIAN', 'M')\n",
      "('JAPANESE', 'F')\n",
      "('JAPANESE', 'M')\n",
      "('KOREAN', 'F')\n",
      "('KOREAN', 'M')\n",
      "('NORDIC', 'F')\n",
      "('NORDIC', 'M')\n",
      "('SLAV', 'F')\n",
      "('SLAV', 'M')\n",
      "('THAI', 'F')\n",
      "('THAI', 'M')\n",
      "('TURKISH', 'F')\n",
      "('TURKISH', 'M')\n"
     ]
    }
   ],
   "source": [
    "# Find any missing F groups\n",
    "missing_groups = [('AFRICAN', 'F'), ('BALTIC', 'F'), ('GERMAN', 'F'), ('HUNGARIAN', 'F'), \n",
    "                    ('ISRAELI', 'F'), ('ITALIAN', 'F'), ('NORDIC', 'F')]\n",
    "\n",
    "unique_groups = list(chosen_clusters['Group'].unique())\n",
    "unique_groups_sorted = sorted(unique_groups + missing_groups)\n",
    "\n",
    "for group in unique_groups_sorted:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AFRICAN', 'F'): ['Adenike', 'Chinwe', 'Olayinka', 'Ramola', 'Eucharia', 'Njeri', 'Olukemi', 'Adwoa', 'Nkechi', 'Folasade']\n",
      "('BALTIC', 'F'): ['Nijole', 'Snieguole', 'Ruta', 'Dace', 'Radvile', 'Audrone', 'Baiba', 'Laima', 'Skaidra', 'Vaida']\n",
      "('GERMAN', 'F'): ['Etheresia', 'Rosmarie', 'Wibke', 'Waltraud', 'Ludgera', 'Brigitta', 'Karola', 'Gerhild', 'Heidemaria', 'Annegret']\n",
      "('HUNGARIAN', 'F'): ['Katelin', 'Erzsebet', 'Ibolya', 'Agota', 'Sarolta', 'Zsofia', 'Eniko', 'Gyongyi', 'Erzsebet', 'Erzsebet']\n",
      "('ISRAELI', 'F'): ['Maayan', 'Tziporah', 'Dganit', 'Tamy', 'Ayelet', 'Anat', 'Raya', 'Ifat', 'Liora', 'Hefziba']\n",
      "('ITALIAN', 'F'): ['Loriana', 'Annagrazia', 'Orietta', 'Lanna', 'Samuela', 'Tambra', 'Ausilia', 'Cherita', 'Concetta', 'Donatella']\n",
      "('NORDIC', 'F'): ['Kirsi', 'Yrsa', 'Anni', 'Jaana', 'Unni', 'Kirstine', 'Guro', 'Anjeli', 'Holmfridur', 'Liv']\n"
     ]
    }
   ],
   "source": [
    "# Print 10 random first names from each ethnicity\n",
    "for group in missing_groups:\n",
    "    selected_rows = df_sorted[(df_sorted[\"Group\"] == group) & (df_sorted['Ethnicity Probability'] > 90)].sample(n=10, replace=True)\n",
    "    selected_rows_df = pd.concat([selected_rows_df, selected_rows], ignore_index=True)\n",
    "    print(f\"{group}: {selected_rows['firstname'].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows_df.to_csv('../data/4c_name_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OPTIONAL: Chart showing gender and ethnicity agreement\n",
    "\n",
    "# ## Creates a df_sorted with information about each cluster\n",
    "\n",
    "# cluster_sizes = df_sorted['Cluster'].value_counts().reset_index().rename(columns={'index': 'Cluster', 'Cluster': 'Size'})\n",
    "\n",
    "# # Calculate the percentage of rows with the highest ethnicity for each cluster\n",
    "# highest_ethnicity_percent = df_sorted.groupby('Cluster')['Ethnicity'].apply(lambda x: (x.value_counts(normalize=True).max() * 100).round(2)).reset_index(name='Ethnicity_Acc')\n",
    "\n",
    "# # Calculate the percentage of rows with the highest gender for each cluster\n",
    "# highest_gender_percent = df_sorted.groupby('Cluster')['Gender'].apply(lambda x: (x.value_counts(normalize=True).max() * 100).round(2)).reset_index(name='Gender_Acc')\n",
    "\n",
    "# # Find the ethnicity with the highest count for each cluster\n",
    "# highest_ethnicity = df_sorted.groupby('Cluster')['Ethnicity'].apply(lambda x: x.value_counts().idxmax()).reset_index(name='Ethnicity')\n",
    "\n",
    "# # Find the gender with the highest count for each cluster\n",
    "# highest_gender = df_sorted.groupby('Cluster')['Gender'].apply(lambda x: x.value_counts().idxmax()).reset_index(name='Genni')\n",
    "\n",
    "# # Merge the DataFrames\n",
    "# result_df = pd.merge(cluster_sizes, highest_ethnicity, on='Cluster')\n",
    "# result_df = pd.merge(result_df, highest_ethnicity_percent, on='Cluster')\n",
    "# result_df = pd.merge(result_df, highest_gender, on='Cluster')\n",
    "# result_df = pd.merge(result_df, highest_gender_percent, on='Cluster')\n",
    "\n",
    "# result_df = result_df.sort_values(by='Cluster').reset_index(drop=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "\n",
    "# # Scatter plot\n",
    "# plt.scatter(result_df['Ethnicity_Acc'], result_df['Gender_Acc'])\n",
    "\n",
    "# # Add labels to the points\n",
    "# for i in range(len(result_df)):\n",
    "#     plt.text(result_df['Ethnicity_Acc'][i], result_df['Gender_Acc'][i], result_df['Ethnicity'][i])\n",
    "\n",
    "# # Set the axis labels\n",
    "# plt.xlabel('Ethnicity Accuracy')\n",
    "# plt.ylabel('Gender Accuracy')\n",
    "\n",
    "# # Set the title\n",
    "# plt.title('Accuracy by Ethnicity and Gender')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
